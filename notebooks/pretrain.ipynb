{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForMaskedLM,  AutoTokenizer, AutoModelForCausalLM, BertTokenizer\n",
    "from transformers import DataCollatorForLanguageModeling,DataCollatorForSeq2Seq\n",
    "from tqdm import tqdm\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"/pretrains/pt/gpt2-chinese-cluecorpussmall\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/pretrains/pt/gpt2-chinese-cluecorpussmall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-eda27db4c7fe4dae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/default to /home/qing/.cache/huggingface/datasets/text/default-eda27db4c7fe4dae/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1e1dbec206436ea521799527792115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2729f4427b9a45b292678f29649bf5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b0de0dd2654b20b48fdbfc8a7e266e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /home/qing/.cache/huggingface/datasets/text/default-eda27db4c7fe4dae/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4a8f0ac0e64b2e859e7a64b935fd68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"text\", data_files=[\"/home/qing/datasets/qidian/我师兄实在太稳健了.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 268604\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_list([ {'text':line.strip()} for line in open(\"/home/qing/datasets/qidian/我师兄实在太稳健了.txt\") if line.strip() != \"\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'《我师兄实在太稳健了》'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['《', '我', '师', '兄', '实', '在', '太', '稳', '健', '了', '》']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"/pretrains/pt/gpt2-chinese-cluecorpussmall\")\n",
    "tokenizer.tokenize(dataset['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7ad58d56a84626abec8d2b60c00840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 134307\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenization_seq2seq(sample):\n",
    "    td = tokenizer(sample['text'])\n",
    "    return td\n",
    "\n",
    "p_dataset = dataset.map(tokenization_seq2seq, batched=True)\n",
    "p_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "new_dataset = deepcopy(p_dataset)\n",
    "new_dataset.set_format(type='torch', columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [tensor([ 101,  517, 2769, 2360, 1040, 2141, 1762, 1922, 4937,  978,  749,  518,\n",
       "           102]),\n",
       "  tensor([ 101,  868, 5442, 8038, 6241, 2495, 3633,  837,  102])],\n",
       " 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [tensor([ 101,  517, 2769, 2360, 1040, 2141, 1762, 1922, 4937,  978,  749,  518,\n",
      "         102]), tensor([ 101,  868, 5442, 8038, 6241, 2495, 3633,  837,  102])], 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 438.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('input_ids', torch.Size([4, 253])), ('attention_mask', torch.Size([4, 253])), ('labels', torch.Size([4, 253]))]\n",
      "[('input_ids', torch.Size([4, 48])), ('attention_mask', torch.Size([4, 48])), ('labels', torch.Size([4, 48]))]\n",
      "[('input_ids', torch.Size([4, 57])), ('attention_mask', torch.Size([4, 57])), ('labels', torch.Size([4, 57]))]\n",
      "[('input_ids', torch.Size([4, 52])), ('attention_mask', torch.Size([4, 52])), ('labels', torch.Size([4, 52]))]\n",
      "[('input_ids', torch.Size([4, 44])), ('attention_mask', torch.Size([4, 44])), ('labels', torch.Size([4, 44]))]\n",
      "[('input_ids', torch.Size([4, 19])), ('attention_mask', torch.Size([4, 19])), ('labels', torch.Size([4, 19]))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from q_snippets.data import sequence_padding\n",
    "class MyCollator:\n",
    "\n",
    "    def __call__(self, features, return_tensors=None):\n",
    "\n",
    "        input_ids = torch.tensor(sequence_padding([x['input_ids'].numpy() for x in features], length=None,force=True)).long()\n",
    "        attention_mask = torch.tensor(sequence_padding([x['attention_mask'].numpy() for x in features], length=None,force=True)).long()\n",
    "        # token_type_ids = torch.tensor(sequence_padding([x.token_type_ids for x in batch], length=self.max_len,force=True)).long()\n",
    "        labels = deepcopy(input_ids)\n",
    "        # decoder_input_ids = input_ids[:,:-1]\n",
    "\n",
    "        return {\n",
    "            'input_ids' : input_ids, 'attention_mask' : attention_mask,\n",
    "            \"labels\":labels, \n",
    "            # 'decoder_input_ids':decoder_input_ids\n",
    "        }\n",
    "        \n",
    "print(new_dataset[:2])\n",
    "dataloader = DataLoader(new_dataset, collate_fn=MyCollator(), batch_size=4)\n",
    "for i, batch in enumerate(tqdm(dataloader, total=5)):\n",
    "    print([(k, v.size()) for k,v in  batch.items() ])\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "model.train().to(device)\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:00<00:00, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.062230110168457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 17.39it/s]                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.7836952209472656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:01, 17.03it/s]\n",
      " 80%|████████  | 4/5 [00:00<00:00, 17.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.2250216007232666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 17.65it/s]                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.022953748703003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:01, 17.55it/s]\n",
      " 80%|████████  | 4/5 [00:00<00:00, 17.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0827327966690063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 17.69it/s]                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.8943085670471191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:01, 17.55it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    for i, batch in enumerate(tqdm(dataloader, total=5)):\n",
    "        if i == 20:\n",
    "            break\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if i % 10 == 0:\n",
    "            print(f\"loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2c969510ce4e9b072345db2134536cec360100592a80dcac73b8aea7d78d86f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
