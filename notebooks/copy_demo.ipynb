{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Mechanism\n",
    "\n",
    "## CopyNet \n",
    "![CopyNet](./imgs/copynet.png)\n",
    "\n",
    "\n",
    "![Summarization](./imgs/summarization_copy.png)\n",
    "\n",
    "[1] Gu, Jiatao, Zhengdong Lu, Hang Li, and Victor O.K. Li. “Incorporating Copying Mechanism in Sequence-to-Sequence Learning.” In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 1631–40. Berlin, Germany: Association for Computational Linguistics, 2016. https://doi.org/10.18653/v1/P16-1154.\n",
    "\n",
    "[2] See, Abigail, Peter J. Liu, and Christopher D. Manning. “Get To The Point: Summarization with Pointer-Generator Networks.” In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 1073–83. Vancouver, Canada: Association for Computational Linguistics, 2017. https://doi.org/10.18653/v1/P17-1099.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys \n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from copy_mechanism import BartConditionalGenerationWithCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartConditionalGenerationWithCopy were not initialized from the model checkpoint at /pretrains/pt/bart_nl2sparql and are newly initialized: ['copy_linear.2.bias', 'copy_linear.0.weight', 'copy_linear.2.weight', 'copy_linear.0.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = BartTokenizer.from_pretrained(\"/pretrains/pt/facebook-bart-base\")\n",
    "# raw_model = BartForConditionalGeneration.from_pretrained(\"/pretrains/pt/facebook-bart-base\")\n",
    "# copy_model = BartConditionalGenerationWithCopy.from_pretrained(\"/pretrains/pt/facebook-bart-base\")\n",
    "\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(\"/pretrains/pt/bart_nl2sparql\")\n",
    "raw_model = BartForConditionalGeneration.from_pretrained(\"/pretrains/pt/bart_nl2sparql\")\n",
    "copy_model = BartConditionalGenerationWithCopy.from_pretrained(\"/pretrains/pt/bart_nl2sparql\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Bart Model Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SELECT DISTINCT?e WHERE {?e <pred:instance_of>?c.?c <pred:name> \"town\".?e <TOID>?pv.?pv <pred:value> \"4000000074573917\".?e <OS_grid_reference>?pv_1.?pv_1 <pred:value> \"SP8778\".  }']\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"\n",
    "# SELECT DISTINCT ?qpv WHERE { \n",
    "#     ?e <pred:instance_of> ?c . ?c <pred:name> \\\"big city\\\" . ?e <postal_code> ?pv_1 . ?pv_1 <pred:value> \\\"54000\\\" . \n",
    "#     ?e <population> ?pv . ?pv <pred:unit> \\\"1\\\" . ?pv <pred:value> \\\"104072\\\"^^xsd:double . \n",
    "#     [ <pred:fact_h> ?e ; <pred:fact_r> <population> ; <pred:fact_t> ?pv ] <point_in_time> ?qpv .  }\n",
    "# \"\"\" \n",
    "# sentence = \"When did the big city whose postal code is 54000 have a population of 104072?\"\n",
    "\n",
    "\"\"\"\n",
    "SELECT DISTINCT ?e WHERE { \n",
    "    ?e <pred:instance_of> ?c . ?c <pred:name> \\\"town\\\" . \n",
    "    ?e <TOID> ?pv . ?pv <pred:value> \\\"4000000074573917\\\" . \n",
    "    ?e <OS_grid_reference> ?pv_1 . ?pv_1 <pred:value> \\\"SP8778\\\" .  }\n",
    "\"\"\"\n",
    "sentence = \"Which town has a TOID of 4000000074573917 and has an OS grid reference of SP8778?\"\n",
    "\n",
    "\n",
    "td = tokenizer(sentence, return_tensors='pt')\n",
    "pred_ids = raw_model.generate(\n",
    "    inputs=td.input_ids, max_length=300, num_beams=1,do_sample=False\n",
    ")\n",
    "print(tokenizer.batch_decode(pred_ids, clean_up_tokenization_spaces=True, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bart With copy mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SELECT D D WHERE <pred>?_1. <TOID>?pv\".?e <OS_grid_reference>?pv_?pv.?pv_1 <pred DISTINCT?pv.?pv <pred DISTINCT?e WHERE {?e <pred DISTINCT?pv.?pv <pred DISTINCT? DISTINCT?pv.?pv < DISTINCT? }']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "td = tokenizer(sentence, return_tensors='pt')\n",
    "pred_ids = copy_model.generate(\n",
    "    inputs=td.input_ids, enable_copy=True, output_attentions=True, output_hidden_states=True,\n",
    "    max_length=300\n",
    ")\n",
    "print(tokenizer.batch_decode(pred_ids,clean_up_tokenization_spaces=True, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2c969510ce4e9b072345db2134536cec360100592a80dcac73b8aea7d78d86f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
